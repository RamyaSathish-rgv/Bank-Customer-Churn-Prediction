# -*- coding: utf-8 -*-
"""Bank Customer Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-BzlP9-zS75WKRgDbxJttciVKuEIaD0T
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = "/content/drive/MyDrive/Churn_Modelling.csv"
df = pd.read_csv(file_path)

df.head()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

X = df.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis=1)
y = df['Exited']

numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts',
                    'HasCrCard', 'IsActiveMember', 'EstimatedSalary']
categorical_features = ['Geography', 'Gender']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

model_pipeline.fit(X_train, y_train)

y_pred = model_pipeline.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2%}")
print(classification_report(y_test, y_pred))

cat_encoder = model_pipeline.named_steps['preprocessor'].named_transformers_['cat']
encoded_cat_names = list(cat_encoder.get_feature_names_out(categorical_features))
all_features = numeric_features + encoded_cat_names

importances = model_pipeline.named_steps['classifier'].feature_importances_
indices = np.argsort(importances)

plt.figure(figsize=(10, 8))
plt.barh(range(len(indices)), importances[indices], color='darkblue', align='center')
plt.yticks(range(len(indices)), [all_features[i] for i in indices])
plt.xlabel('Importance Score')
plt.show()

from sklearn.model_selection import GridSearchCV

param_grid = {
    'classifier__n_estimators': [100, 200],
    'classifier__max_depth': [10, 20, None],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__criterion': ['gini', 'entropy']
}


grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy', verbose=1)


grid_search.fit(X_train, y_train)


print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Training Accuracy: {grid_search.best_score_:.2%}")

best_model = grid_search.best_estimator_
y_pred_tuned = best_model.predict(X_test)

print(f"Final Test Accuracy: {accuracy_score(y_test, y_pred_tuned):.2%}")
print(classification_report(y_test, y_pred_tuned))

new_customer = {
    'CreditScore': 600,
    'Geography': 'France',
    'Gender': 'Male',
    'Age': 40,
    'Tenure': 3,
    'Balance': 60000,
    'NumOfProducts': 2,
    'HasCrCard': 1,
    'IsActiveMember': 1,
    'EstimatedSalary': 50000
}


input_df = pd.DataFrame([new_customer])

new_customer_data = {
    'CreditScore': 600,
    'Geography': 'France',
    'Gender': 'Male',
    'Age': 40,
    'Tenure': 3,
    'Balance': 60000,
    'NumOfProducts': 2,
    'HasCrCard': 1,
    'IsActiveMember': 1,
    'EstimatedSalary': 50000
}

input_df = pd.DataFrame([new_customer_data])

prediction = model_pipeline.predict(input_df)
probability = model_pipeline.predict_proba(input_df)

if prediction[0] == 1:
    print(f"Prediction: Customer is likely to CHURN.")
else:
    print(f"Prediction: Customer is likely to STAY.")

print(f"Confidence: {probability[0][prediction[0]]:.2%}")

new_customer_data = {
    'CreditScore': 500,
    'Geography': 'Germany',
    'Gender': 'Female',
    'Age': 55,
    'Tenure': 1,
    'Balance': 150000,
    'NumOfProducts': 4,
    'HasCrCard': 1,
    'IsActiveMember': 0,
    'EstimatedSalary': 120000
}

input_df = pd.DataFrame([new_customer_data])

prediction = model_pipeline.predict(input_df)
probability = model_pipeline.predict_proba(input_df)

if prediction[0] == 1:
    print(f"Prediction: Customer is likely to CHURN.")
else:
    print(f"Prediction: Customer is likely to STAY.")

print(f"Confidence: {probability[0][prediction[0]]:.2%}")

import pickle

with open("model.pkl", "wb") as f:
    pickle.dump(model_pipeline, f)

print("Saved model.pkl (full pipeline)")

from google.colab import files
files.download("model.pkl")

print(X.columns)